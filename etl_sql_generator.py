"""
ETL ê²€ì¦ SQL ìë™ ìƒì„± ì—”ì§„

LLM(Gemini)ì„ í™œìš©í•˜ì—¬ ì†ŒìŠ¤/íƒ€ê²Ÿ í…Œì´ë¸” ë©”íƒ€ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ
ë°ì´í„° ê²€ì¦ ì¿¼ë¦¬ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.

ìƒì„±í•˜ëŠ” ê²€ì¦ ì¿¼ë¦¬:
  1. row_count_check   - ê±´ìˆ˜ ë¹„êµ
  2. pk_missing_check  - PK ëˆ„ë½ ê²€ì¦ (ì†ŒìŠ¤ì— ìˆê³  íƒ€ê²Ÿì— ì—†ëŠ” ê²ƒ)
  3. null_check        - ì£¼ìš” ì»¬ëŸ¼ NULL ì²´í¬
  4. duplicate_check   - íƒ€ê²Ÿ í…Œì´ë¸” PK ì¤‘ë³µ ê²€ì¦
  5. checksum_check    - ì²´í¬ì„¬ ë¹„êµ
  6. full_diff_check   - ì „ì²´ ë°ì´í„° ë¶ˆì¼ì¹˜ í™•ì¸
"""

import json
import os
import re
import textwrap
from typing import Optional

from dotenv import load_dotenv

load_dotenv()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LLM ì´ˆê¸°í™”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _get_llm():
    """LLM ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (LLM_PROVIDER í™˜ê²½ë³€ìˆ˜ë¡œ í”„ë¡œë°”ì´ë” ì„ íƒ ê°€ëŠ¥)"""
    from aetl_llm import get_llm
    return get_llm()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”íƒ€ë°ì´í„° í¬ë§· í—¬í¼
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _format_columns(meta: dict) -> str:
    """ì»¬ëŸ¼ ëª©ë¡ì„ í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    lines = []
    for col in meta.get("columns", []):
        pk_mark = " [PK]" if col.get("pk") else ""
        nn_mark = " NOT NULL" if not col.get("nullable", True) else ""
        type_str = f" {col['type']}" if col.get("type") else ""
        desc = f"  -- {col['description']}" if col.get("description") else ""
        lines.append(f"  {col['name']}{type_str}{pk_mark}{nn_mark}{desc}")
    return "\n".join(lines)


def _format_mapping(mapping: list[dict]) -> str:
    """ì»¬ëŸ¼ ë§¤í•‘ì„ í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if not mapping:
        return "  (ë§¤í•‘ ì •ë³´ ì—†ìŒ - ë™ì¼ ì»¬ëŸ¼ëª… ê°€ì •)"
    lines = []
    for m in mapping:
        transform = f" â†’ ë³€í™˜: {m['transform']}" if m.get("transform") else ""
        lines.append(f"  {m['source_col']} â†’ {m['target_col']}{transform}")
    return "\n".join(lines)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_GENERATION_PROMPT = """ë‹¹ì‹ ì€ ETL ë°ì´í„° ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì†ŒìŠ¤ í…Œì´ë¸”ì—ì„œ íƒ€ê²Ÿ í…Œì´ë¸”ë¡œ ETL ì ì¬ í›„ ë°ì´í„° í’ˆì§ˆì„ ê²€ì¦í•˜ëŠ” SQL ì¿¼ë¦¬ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

## ì†ŒìŠ¤ í…Œì´ë¸”: {source_table}
{source_columns}
PK: {source_pk}

## íƒ€ê²Ÿ í…Œì´ë¸”: {target_table}
{target_columns}
PK: {target_pk}

## ì»¬ëŸ¼ ë§¤í•‘
{column_mapping}

## DB ì¢…ë¥˜: {db_type}
{db_notes}

## ìƒì„± ê·œì¹™
1. ì‹¤ì œ ì‹¤í–‰ ê°€ëŠ¥í•œ SQLë§Œ ìƒì„± (ë¬¸ë²• ì˜¤ë¥˜ ì—†ì„ ê²ƒ)
2. ê° ì¿¼ë¦¬ì— í•œêµ­ì–´ ì£¼ì„ í¬í•¨
3. {db_type} ë¬¸ë²• ì‚¬ìš©
4. ì»¬ëŸ¼ ë§¤í•‘ì´ ìˆìœ¼ë©´ ë§¤í•‘ëœ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ë¹„êµ
5. PKê°€ ì—†ìœ¼ë©´ ëª¨ë“  ì»¬ëŸ¼ì„ ë¹„êµ ëŒ€ìƒìœ¼ë¡œ ì‚¬ìš©

## ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥, ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì—†ì´)
{{
  "row_count_check": {{
    "description": "ì†ŒìŠ¤/íƒ€ê²Ÿ ê±´ìˆ˜ ë¹„êµ",
    "sql": "SELECT 'ì†ŒìŠ¤' AS êµ¬ë¶„, COUNT(*) AS ê±´ìˆ˜ FROM {source_table}\\nUNION ALL\\nSELECT 'íƒ€ê²Ÿ' AS êµ¬ë¶„, COUNT(*) AS ê±´ìˆ˜ FROM {target_table};"
  }},
  "pk_missing_check": {{
    "description": "ì†ŒìŠ¤ì— ìˆì§€ë§Œ íƒ€ê²Ÿì— ì—†ëŠ” PK",
    "sql": "..."
  }},
  "null_check": {{
    "description": "ì£¼ìš” ì»¬ëŸ¼ NULL ê±´ìˆ˜ í™•ì¸",
    "sql": "..."
  }},
  "duplicate_check": {{
    "description": "íƒ€ê²Ÿ PK ì¤‘ë³µ ê²€ì¦",
    "sql": "..."
  }},
  "checksum_check": {{
    "description": "ë°ì´í„° ì²´í¬ì„¬ ë¹„êµ",
    "sql": "..."
  }},
  "full_diff_check": {{
    "description": "ì†ŒìŠ¤/íƒ€ê²Ÿ ë°ì´í„° ë¶ˆì¼ì¹˜ í™•ì¸",
    "sql": "..."
  }}
}}"""

_DB_NOTES = {
    "oracle": textwrap.dedent("""
    Oracle ì „ìš© ì£¼ì˜ì‚¬í•­:
    - EXCEPT ëŒ€ì‹  MINUS ì‚¬ìš©
    - í–‰ ì œí•œ: FETCH FIRST N ROWS ONLY
    - ì²´í¬ì„¬: ORA_HASH() ë˜ëŠ” STANDARD_HASH() ì‚¬ìš©
    - ë¬¸ìì—´ ì—°ê²°: || ì‚¬ìš©
    - NULL ë¹„êµ: NVL() ë˜ëŠ” DECODE() ì‚¬ìš©
    - í˜„ì¬ ë‚ ì§œ: SYSDATE
    """).strip(),

    "mariadb": textwrap.dedent("""
    MariaDB/MySQL ì „ìš© ì£¼ì˜ì‚¬í•­:
    - EXCEPT ë¬¸ë²• ì‚¬ìš© ê°€ëŠ¥ (MariaDB 10.3+)
    - í–‰ ì œí•œ: LIMIT N
    - ì²´í¬ì„¬: MD5() ë˜ëŠ” CRC32() ì‚¬ìš©
    - ë¬¸ìì—´ ì—°ê²°: CONCAT() ì‚¬ìš©
    - NULL ë¹„êµ: IFNULL() ë˜ëŠ” COALESCE() ì‚¬ìš©
    - í˜„ì¬ ë‚ ì§œ: NOW()
    """).strip(),

    "postgresql": textwrap.dedent("""
    PostgreSQL ì „ìš© ì£¼ì˜ì‚¬í•­:
    - EXCEPT ì‚¬ìš© ê°€ëŠ¥
    - í–‰ ì œí•œ: LIMIT N
    - ì²´í¬ì„¬: MD5()::text ë˜ëŠ” hashtext() ì‚¬ìš©
    - ë¬¸ìì—´ ì—°ê²°: || ë˜ëŠ” CONCAT() ì‚¬ìš©
    - NULL ë¹„êµ: COALESCE() ì‚¬ìš©
    - í˜„ì¬ ë‚ ì§œ: NOW()
    """).strip(),
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í•µì‹¬ ìƒì„± í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def generate_validation_queries(
    source_meta: dict,
    target_meta: dict,
    column_mapping: list[dict] | None = None,
    db_type: str = "oracle",
    llm=None,
) -> dict:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ETL ê²€ì¦ SQL ì¿¼ë¦¬ ìƒì„±

    Args:
        source_meta:    ì†ŒìŠ¤ í…Œì´ë¸” ë©”íƒ€ë°ì´í„° (etl_metadata_parser ë°˜í™˜ê°’)
        target_meta:    íƒ€ê²Ÿ í…Œì´ë¸” ë©”íƒ€ë°ì´í„°
        column_mapping: ì»¬ëŸ¼ ë§¤í•‘ ëª©ë¡ (ì—†ìœ¼ë©´ ë™ì¼ ì»¬ëŸ¼ëª… ê°€ì •)
        db_type:        'oracle' | 'mariadb' | 'postgresql'
        llm:            LLM ì¸ìŠ¤í„´ìŠ¤ (Noneì´ë©´ ìë™ ìƒì„±)

    Returns:
        {
          "row_count_check":  {"description": ..., "sql": ...},
          "pk_missing_check": {"description": ..., "sql": ...},
          ...
        }
    """
    if llm is None:
        llm = _get_llm()

    source_table = source_meta["table_name"]
    target_table = target_meta["table_name"]
    source_pk = ", ".join(source_meta.get("pk_columns", [])) or "(PK ì—†ìŒ)"
    target_pk = ", ".join(target_meta.get("pk_columns", [])) or "(PK ì—†ìŒ)"

    prompt = _GENERATION_PROMPT.format(
        source_table=source_table,
        source_columns=_format_columns(source_meta),
        source_pk=source_pk,
        target_table=target_table,
        target_columns=_format_columns(target_meta),
        target_pk=target_pk,
        column_mapping=_format_mapping(column_mapping or []),
        db_type=db_type.upper(),
        db_notes=_DB_NOTES.get(db_type.lower(), ""),
    )

    response = llm.invoke(prompt)
    raw = response.content if hasattr(response, "content") else str(response)

    return _parse_llm_response(raw, source_meta, target_meta, db_type, column_mapping)


def _parse_llm_response(
    raw: str,
    source_meta: dict,
    target_meta: dict,
    db_type: str,
    column_mapping: list[dict] | None,
) -> dict:
    """LLM ì‘ë‹µì—ì„œ JSON íŒŒì‹±, ì‹¤íŒ¨ ì‹œ rule-based í´ë°±"""
    # JSON ë¸”ë¡ ì¶”ì¶œ
    text = raw.strip()
    json_match = re.search(r"```(?:json)?\s*([\s\S]*?)```", text)
    if json_match:
        text = json_match.group(1).strip()

    # ìˆœìˆ˜ JSON ì‹œì‘ì  ì°¾ê¸°
    brace_start = text.find("{")
    brace_end = text.rfind("}")
    if brace_start != -1 and brace_end != -1:
        text = text[brace_start:brace_end + 1]

    try:
        result = json.loads(text)
        # ê° í•­ëª©ì— sql í‚¤ í™•ì¸
        expected_keys = [
            "row_count_check", "pk_missing_check", "null_check",
            "duplicate_check", "checksum_check", "full_diff_check",
        ]
        for k in expected_keys:
            if k not in result:
                result[k] = {"description": k, "sql": "-- LLMì´ ìƒì„±í•˜ì§€ ì•Šì€ ì¿¼ë¦¬"}
        return result
    except json.JSONDecodeError:
        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ rule-based í´ë°±
        return _generate_fallback_queries(source_meta, target_meta, db_type, column_mapping)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Rule-based í´ë°± (LLM ì—†ì´ë„ ê¸°ë³¸ ì¿¼ë¦¬ ìƒì„±)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _generate_fallback_queries(
    source_meta: dict,
    target_meta: dict,
    db_type: str,
    column_mapping: list[dict] | None,
) -> dict:
    """LLM ì‹¤íŒ¨ ì‹œ í…œí”Œë¦¿ ê¸°ë°˜ìœ¼ë¡œ ê²€ì¦ ì¿¼ë¦¬ ìƒì„±"""
    src = source_meta["table_name"]
    tgt = target_meta["table_name"]
    src_pk = source_meta.get("pk_columns", [])
    tgt_pk = target_meta.get("pk_columns", [])

    # ë§¤í•‘: source_col â†’ target_col
    col_map = {}
    if column_mapping:
        for m in column_mapping:
            if m.get("source_col") and m.get("target_col"):
                col_map[m["source_col"]] = m["target_col"]

    # DB ì¢…ë¥˜ë³„ í•¨ìˆ˜
    is_oracle = db_type.lower() == "oracle"
    is_postgres = db_type.lower() in ("postgresql", "postgres")
    except_kw = "MINUS" if is_oracle else "EXCEPT"
    limit_clause = "FETCH FIRST 100 ROWS ONLY" if is_oracle else "LIMIT 100"

    # â”€â”€ 1. row_count_check â”€â”€
    row_count_sql = f"""-- ì†ŒìŠ¤/íƒ€ê²Ÿ ê±´ìˆ˜ ë¹„êµ
SELECT 'ì†ŒìŠ¤({src})' AS êµ¬ë¶„, COUNT(*) AS ê±´ìˆ˜ FROM {src}
UNION ALL
SELECT 'íƒ€ê²Ÿ({tgt})' AS êµ¬ë¶„, COUNT(*) AS ê±´ìˆ˜ FROM {tgt};"""

    # â”€â”€ 2. pk_missing_check â”€â”€
    if src_pk:
        pk_select_src = ", ".join(src_pk)
        pk_select_tgt = ", ".join(col_map.get(p, p) for p in src_pk)
        pk_missing_sql = f"""-- ì†ŒìŠ¤ì— ìˆì§€ë§Œ íƒ€ê²Ÿì— ì—†ëŠ” PK
SELECT {pk_select_src}
FROM {src}
{except_kw}
SELECT {pk_select_tgt}
FROM {tgt};"""
    else:
        pk_missing_sql = f"-- PK ì •ë³´ê°€ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.\n-- SELECT * FROM {src} MINUS SELECT * FROM {tgt};"

    # â”€â”€ 3. null_check â”€â”€
    # NOT NULL ë˜ëŠ” PK ì»¬ëŸ¼ì— ëŒ€í•´ NULL ì²´í¬
    key_cols_src = [c["name"] for c in source_meta["columns"] if c.get("pk") or not c.get("nullable", True)][:5]
    key_cols_tgt = [col_map.get(c, c) for c in key_cols_src]
    if not key_cols_src:
        key_cols_src = [source_meta["columns"][0]["name"]] if source_meta["columns"] else ["*"]
        key_cols_tgt = [col_map.get(key_cols_src[0], key_cols_src[0])]

    null_parts_src = "\n  OR ".join([f"{c} IS NULL" for c in key_cols_src])
    null_parts_tgt = "\n  OR ".join([f"{c} IS NULL" for c in key_cols_tgt])

    null_check_sql = f"""-- ì†ŒìŠ¤ ì£¼ìš” ì»¬ëŸ¼ NULL ê±´ìˆ˜ í™•ì¸
SELECT
  {chr(10).join([f"  SUM(CASE WHEN {c} IS NULL THEN 1 ELSE 0 END) AS {c}_NULL_CNT," for c in key_cols_src]).rstrip(',')}
FROM {src};

-- íƒ€ê²Ÿ ì£¼ìš” ì»¬ëŸ¼ NULL ê±´ìˆ˜ í™•ì¸
SELECT
  {chr(10).join([f"  SUM(CASE WHEN {c} IS NULL THEN 1 ELSE 0 END) AS {c}_NULL_CNT," for c in key_cols_tgt]).rstrip(',')}
FROM {tgt};"""

    # â”€â”€ 4. duplicate_check â”€â”€
    if tgt_pk:
        pk_list = ", ".join(tgt_pk)
        duplicate_sql = f"""-- íƒ€ê²Ÿ í…Œì´ë¸” PK ì¤‘ë³µ ê²€ì¦
SELECT {pk_list}, COUNT(*) AS CNT
FROM {tgt}
GROUP BY {pk_list}
HAVING COUNT(*) > 1;"""
    else:
        duplicate_sql = f"-- PK ì •ë³´ê°€ ì—†ì–´ ì „ì²´ ì¤‘ë³µ ì²´í¬\nSELECT COUNT(*) AS TOTAL, COUNT(DISTINCT ROWID) AS DISTINCT_CNT FROM {tgt};" if is_oracle \
            else f"-- PK ì •ë³´ê°€ ì—†ì–´ ì „ì²´ ì¤‘ë³µ ì²´í¬\nSELECT COUNT(*) AS TOTAL FROM {tgt};"

    # â”€â”€ 5. checksum_check â”€â”€
    # ë¹„êµ ê°€ëŠ¥í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ (ë§¤í•‘ ê³ ë ¤)
    src_cols_for_hash = [c["name"] for c in source_meta["columns"] if c.get("pk")][:5]
    tgt_cols_for_hash = [col_map.get(c, c) for c in src_cols_for_hash]
    if not src_cols_for_hash:
        src_cols_for_hash = [c["name"] for c in source_meta["columns"]][:5]
        tgt_cols_for_hash = [col_map.get(c, c) for c in src_cols_for_hash]

    if is_oracle:
        src_hash_expr = " || '|' || ".join([f"NVL(TO_CHAR({c}),'NULL')" for c in src_cols_for_hash])
        tgt_hash_expr = " || '|' || ".join([f"NVL(TO_CHAR({c}),'NULL')" for c in tgt_cols_for_hash])
        checksum_sql = f"""-- ì†ŒìŠ¤/íƒ€ê²Ÿ ì²´í¬ì„¬ ë¹„êµ
SELECT 'ì†ŒìŠ¤' AS êµ¬ë¶„, SUM(ORA_HASH({src_hash_expr})) AS CHECKSUM FROM {src}
UNION ALL
SELECT 'íƒ€ê²Ÿ' AS êµ¬ë¶„, SUM(ORA_HASH({tgt_hash_expr})) AS CHECKSUM FROM {tgt};"""
    elif is_postgres:
        src_concat = " || '|' || ".join([f"COALESCE(CAST({c} AS TEXT),'NULL')" for c in src_cols_for_hash])
        tgt_concat = " || '|' || ".join([f"COALESCE(CAST({c} AS TEXT),'NULL')" for c in tgt_cols_for_hash])
        checksum_sql = f"""-- ì†ŒìŠ¤/íƒ€ê²Ÿ ì²´í¬ì„¬ ë¹„êµ
SELECT 'ì†ŒìŠ¤' AS êµ¬ë¶„, SUM(('x' || LEFT(MD5({src_concat}), 8))::bit(32)::int) AS CHECKSUM FROM {src}
UNION ALL
SELECT 'íƒ€ê²Ÿ' AS êµ¬ë¶„, SUM(('x' || LEFT(MD5({tgt_concat}), 8))::bit(32)::int) AS CHECKSUM FROM {tgt};"""
    else:
        src_concat = ", '|', ".join([f"IFNULL(CAST({c} AS CHAR),'NULL')" for c in src_cols_for_hash])
        tgt_concat = ", '|', ".join([f"IFNULL(CAST({c} AS CHAR),'NULL')" for c in tgt_cols_for_hash])
        checksum_sql = f"""-- ì†ŒìŠ¤/íƒ€ê²Ÿ ì²´í¬ì„¬ ë¹„êµ
SELECT 'ì†ŒìŠ¤' AS êµ¬ë¶„, SUM(CRC32(CONCAT({src_concat}))) AS CHECKSUM FROM {src}
UNION ALL
SELECT 'íƒ€ê²Ÿ' AS êµ¬ë¶„, SUM(CRC32(CONCAT({tgt_concat}))) AS CHECKSUM FROM {tgt};"""

    # â”€â”€ 6. full_diff_check â”€â”€
    if src_pk and tgt_pk:
        src_pk_str = ", ".join([f"S.{p}" for p in src_pk])
        join_cond = " AND ".join([f"S.{sp} = T.{tp}" for sp, tp in zip(src_pk, tgt_pk)])

        # ë¹„êµ ì»¬ëŸ¼ (PK ì œì™¸, ìµœëŒ€ 10ê°œ)
        compare_cols_src = [c["name"] for c in source_meta["columns"] if c["name"] not in src_pk][:10]
        compare_cols_tgt = [col_map.get(c, c) for c in compare_cols_src]

        diff_conditions = []
        for sc, tc in zip(compare_cols_src, compare_cols_tgt):
            if is_oracle:
                diff_conditions.append(f"      DECODE(S.{sc}, T.{tc}, 0, 1) = 1")
            else:
                diff_conditions.append(f"      (S.{sc} <> T.{tc} OR (S.{sc} IS NULL) <> (T.{tc} IS NULL))")

        diff_cond_str = "\n   OR ".join(diff_conditions) if diff_conditions else "1=0 -- ë¹„êµí•  ì»¬ëŸ¼ ì—†ìŒ"

        full_diff_sql = f"""-- ì†ŒìŠ¤/íƒ€ê²Ÿ ë°ì´í„° ë¶ˆì¼ì¹˜ í™•ì¸
SELECT
  {src_pk_str},
  'MISMATCH' AS STATUS
FROM {src} S
JOIN {tgt} T ON {join_cond}
WHERE
   {diff_cond_str}
{limit_clause};"""
    else:
        full_diff_sql = f"""-- PK ì—†ìŒ: ì „ì²´ ì†ŒìŠ¤-íƒ€ê²Ÿ ì°¨ì´ í™•ì¸
-- ì†ŒìŠ¤ì—ë§Œ ìˆëŠ” ë°ì´í„°
SELECT * FROM {src}
{except_kw}
SELECT * FROM {tgt};"""

    return {
        "row_count_check": {
            "description": "ì†ŒìŠ¤/íƒ€ê²Ÿ ê±´ìˆ˜ ë¹„êµ",
            "sql": row_count_sql,
        },
        "pk_missing_check": {
            "description": "ì†ŒìŠ¤ì— ìˆì§€ë§Œ íƒ€ê²Ÿì— ì—†ëŠ” PK",
            "sql": pk_missing_sql,
        },
        "null_check": {
            "description": "ì£¼ìš” ì»¬ëŸ¼ NULL ê±´ìˆ˜ í™•ì¸",
            "sql": null_check_sql,
        },
        "duplicate_check": {
            "description": "íƒ€ê²Ÿ í…Œì´ë¸” PK ì¤‘ë³µ ê²€ì¦",
            "sql": duplicate_sql,
        },
        "checksum_check": {
            "description": "ì†ŒìŠ¤/íƒ€ê²Ÿ ì²´í¬ì„¬ ë¹„êµ",
            "sql": checksum_sql,
        },
        "full_diff_check": {
            "description": "ì†ŒìŠ¤/íƒ€ê²Ÿ ë°ì´í„° ë¶ˆì¼ì¹˜ í™•ì¸",
            "sql": full_diff_sql,
        },
    }


def generate_validation_queries_no_llm(
    source_meta: dict,
    target_meta: dict,
    column_mapping: list[dict] | None = None,
    db_type: str = "oracle",
) -> dict:
    """LLM ì—†ì´ Rule-basedë¡œë§Œ ê²€ì¦ ì¿¼ë¦¬ ìƒì„± (ë¹ ë¥¸ ê²°ê³¼, ë‚®ì€ í’ˆì§ˆ)"""
    return _generate_fallback_queries(source_meta, target_meta, db_type, column_mapping)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì¶”ê°€ ìœ í‹¸ë¦¬í‹°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

QUERY_LABELS = {
    "row_count_check":  "ê±´ìˆ˜ ë¹„êµ",
    "pk_missing_check": "PK ëˆ„ë½ ê²€ì¦",
    "null_check":       "NULL ì²´í¬",
    "duplicate_check":  "ì¤‘ë³µ ê²€ì¦",
    "checksum_check":   "ì²´í¬ì„¬ ë¹„êµ",
    "full_diff_check":  "ì „ì²´ ë°ì´í„° ë¹„êµ",
}

QUERY_ICONS = {
    "row_count_check":  "ğŸ“Š",
    "pk_missing_check": "ğŸ”",
    "null_check":       "âš ï¸",
    "duplicate_check":  "ğŸ”„",
    "checksum_check":   "ğŸ”",
    "full_diff_check":  "âš–ï¸",
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# AI Rule Suggester  (aetl_profiler í”„ë¡œíŒŒì¼ ê¸°ë°˜)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def suggest_validation_rules(
    source_profile: dict,
    target_profile: dict | None = None,
    db_type: str = "oracle",
) -> list[dict]:
    """
    ë°ì´í„° í”„ë¡œíŒŒì¼(aetl_profiler.profile_table ê²°ê³¼)ì„ ë¶„ì„í•˜ì—¬
    Tier 1~3 ê²€ì¦ ê·œì¹™ì„ ìë™ ì œì•ˆí•©ë‹ˆë‹¤.

    Args:
        source_profile: aetl_profiler.profile_table() ë°˜í™˜ê°’
        target_profile: íƒ€ê²Ÿ í”„ë¡œíŒŒì¼ (ì—†ìœ¼ë©´ ì†ŒìŠ¤ ê¸°ë°˜ë§Œ ìƒì„±)
        db_type:        'oracle' | 'mariadb' | 'postgresql'

    Returns:
        [
          {
            "rule_name": str,
            "rule_type": str,       # null_check | range_check | uniqueness_check | ...
            "tier": int,            # 1:ê¸°ìˆ ê²€ì¦ 2:ì •í•©ì„± 3:ë¹„ì¦ˆë‹ˆìŠ¤
            "severity": str,        # CRITICAL | WARNING | INFO
            "source_table": str,
            "target_table": str | None,
            "target_column": str | None,
            "sql": str,             # ì‹¤í–‰ ê°€ëŠ¥í•œ ê²€ì¦ SQL
            "reason": str,          # ìë™ ìƒì„± ê·¼ê±°
            "auto_generated": bool,
          }
        ]
    """
    is_oracle = db_type.lower() == "oracle"
    is_postgres = db_type.lower() in ("postgresql", "postgres")
    src_tbl   = source_profile["table_name"]
    tgt_tbl   = target_profile["table_name"] if target_profile else None
    rules: list[dict] = []

    # â”€â”€ Tier 2: ê±´ìˆ˜ ë¹„êµ (í•­ìƒ ìƒì„±) â”€â”€
    if tgt_tbl:
        rules.append({
            "rule_name":    f"{src_tbl}_vs_{tgt_tbl}_ROW_COUNT",
            "rule_type":    "row_count_match",
            "tier":         2,
            "severity":     "CRITICAL",
            "source_table": src_tbl,
            "target_table": tgt_tbl,
            "target_column": None,
            "sql": (
                f"SELECT ABS(s.cnt - t.cnt) AS diff\n"
                f"FROM (SELECT COUNT(*) AS cnt FROM {src_tbl}) s,\n"
                f"     (SELECT COUNT(*) AS cnt FROM {tgt_tbl}) t\n"
                f"-- PASS ì¡°ê±´: diff = 0"
            ),
            "reason": "ì†ŒìŠ¤Â·íƒ€ê²Ÿ ì „ì²´ ê±´ìˆ˜ê°€ ë°˜ë“œì‹œ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.",
            "auto_generated": True,
        })

    for col in source_profile.get("columns", []):
        cname   = col["name"]
        ctype   = col.get("type", "")
        domain  = col.get("inferred_domain", "unknown")
        null_p  = col.get("null_pct", 0.0)
        dist_c  = col.get("distinct_count", 0)
        row_c   = source_profile.get("row_count", 0)
        min_v   = col.get("min")
        max_v   = col.get("max")

        # â”€â”€ Tier 1: NULL ì²´í¬ â”€â”€
        # NOT NULL ì´ì–´ì•¼ í•˜ëŠ” ì»¬ëŸ¼ì— NULLì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°
        if null_p == 0.0 and domain in ("id", "code", "amount", "date"):
            severity = "CRITICAL" if domain in ("id",) else "WARNING"
            sql = (
                f"SELECT COUNT(*) AS null_cnt\n"
                f"FROM {src_tbl}\n"
                f"WHERE {cname} IS NULL\n"
                f"-- PASS ì¡°ê±´: null_cnt = 0"
            )
            rules.append({
                "rule_name":     f"{src_tbl}_{cname}_NULL_CHECK",
                "rule_type":     "null_check",
                "tier":          1,
                "severity":      severity,
                "source_table":  src_tbl,
                "target_table":  tgt_tbl,
                "target_column": cname,
                "sql":           sql,
                "reason":        f"'{cname}'ì€ í˜„ì¬ NULLì´ 0ê±´ì´ë¯€ë¡œ NOT NULL ì¡°ê±´ ì ìš© ê¶Œì¥.",
                "auto_generated": True,
            })

        # NULL ë¹„ìœ¨ì´ ë†’ì€ ì»¬ëŸ¼ì— ëŒ€í•œ ì„ê³„ì¹˜ ì²´í¬
        if null_p > 0.3:
            sql = (
                f"SELECT ROUND(SUM(CASE WHEN {cname} IS NULL THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) AS null_pct\n"
                f"FROM {src_tbl}\n"
                f"-- PASS ì¡°ê±´: null_pct <= {round(null_p * 100 + 10, 1)} (í˜„ì¬ ê¸°ì¤€ +10%)"
            )
            rules.append({
                "rule_name":     f"{src_tbl}_{cname}_NULL_PCT_CHECK",
                "rule_type":     "null_check",
                "tier":          1,
                "severity":      "WARNING",
                "source_table":  src_tbl,
                "target_table":  tgt_tbl,
                "target_column": cname,
                "sql":           sql,
                "threshold":     round(null_p * 100 + 10, 1),
                "reason":        f"'{cname}' NULL ë¹„ìœ¨ì´ {round(null_p*100,1)}%ë¡œ ë†’ìŠµë‹ˆë‹¤. ì„ê³„ì¹˜ ëª¨ë‹ˆí„°ë§ ê¶Œì¥.",
                "auto_generated": True,
            })

        # â”€â”€ Tier 1: ìœ ì¼ì„±(PK í›„ë³´) ì²´í¬ â”€â”€
        if row_c > 0 and dist_c == row_c and dist_c > 100:
            sql = (
                f"SELECT {cname}, COUNT(*) AS dup_cnt\n"
                f"FROM {src_tbl}\n"
                f"GROUP BY {cname}\n"
                f"HAVING COUNT(*) > 1\n"
                f"-- PASS ì¡°ê±´: 0ê±´"
            )
            rules.append({
                "rule_name":     f"{src_tbl}_{cname}_UNIQUENESS_CHECK",
                "rule_type":     "uniqueness_check",
                "tier":          1,
                "severity":      "CRITICAL",
                "source_table":  src_tbl,
                "target_table":  tgt_tbl,
                "target_column": cname,
                "sql":           sql,
                "reason":        f"'{cname}' distinct_count={dist_c} = row_count ì´ë¯€ë¡œ PK í›„ë³´ ì»¬ëŸ¼ì…ë‹ˆë‹¤.",
                "auto_generated": True,
            })

        # â”€â”€ Tier 3: ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ â€” ê¸ˆì•¡ ì–‘ìˆ˜ ì²´í¬ â”€â”€
        if domain == "amount" and min_v is not None:
            try:
                min_num = float(min_v)
                if min_num >= 0:
                    sql = (
                        f"SELECT COUNT(*) AS negative_cnt\n"
                        f"FROM {src_tbl}\n"
                        f"WHERE {cname} < 0\n"
                        f"-- PASS ì¡°ê±´: negative_cnt = 0"
                    )
                    rules.append({
                        "rule_name":     f"{src_tbl}_{cname}_POSITIVE_CHECK",
                        "rule_type":     "range_check",
                        "tier":          3,
                        "severity":      "WARNING",
                        "source_table":  src_tbl,
                        "target_table":  tgt_tbl,
                        "target_column": cname,
                        "sql":           sql,
                        "reason":        f"'{cname}'ì€ ê¸ˆì•¡ ê³„ì—´ ì»¬ëŸ¼ìœ¼ë¡œ ìŒìˆ˜ ë¶ˆê°€ ì¡°ê±´ ì ìš© ê¶Œì¥.",
                        "auto_generated": True,
                    })
            except (ValueError, TypeError):
                pass

        # â”€â”€ Tier 3: ë‚ ì§œ ë²”ìœ„ ë“œë¦¬í”„íŠ¸ ì²´í¬ â”€â”€
        if domain == "date" and min_v and max_v:
            if is_oracle:
                sql = (
                    f"SELECT COUNT(*) AS future_cnt\n"
                    f"FROM {src_tbl}\n"
                    f"WHERE {cname} > SYSDATE + 1\n"
                    f"-- PASS ì¡°ê±´: future_cnt = 0"
                )
            elif is_postgres:
                sql = (
                    f"SELECT COUNT(*) AS future_cnt\n"
                    f"FROM {src_tbl}\n"
                    f"WHERE {cname} > NOW() + INTERVAL '1 day'\n"
                    f"-- PASS ì¡°ê±´: future_cnt = 0"
                )
            else:
                sql = (
                    f"SELECT COUNT(*) AS future_cnt\n"
                    f"FROM {src_tbl}\n"
                    f"WHERE {cname} > DATE_ADD(NOW(), INTERVAL 1 DAY)\n"
                    f"-- PASS ì¡°ê±´: future_cnt = 0"
                )
            rules.append({
                "rule_name":     f"{src_tbl}_{cname}_FUTURE_DATE_CHECK",
                "rule_type":     "range_check",
                "tier":          3,
                "severity":      "INFO",
                "source_table":  src_tbl,
                "target_table":  tgt_tbl,
                "target_column": cname,
                "sql":           sql,
                "reason":        f"'{cname}'ì€ ë‚ ì§œ ì»¬ëŸ¼ì…ë‹ˆë‹¤. ë¯¸ë˜ ë‚ ì§œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ê¶Œì¥.",
                "auto_generated": True,
            })

        # â”€â”€ Tier 2: íƒ€ê²Ÿê³¼ ì»¬ëŸ¼ë³„ í•©ê³„ ë¹„êµ (ê¸ˆì•¡Â·ìˆ˜ëŸ‰) â”€â”€
        if tgt_tbl and domain in ("amount", "count"):
            null_fn = "NVL" if is_oracle else "COALESCE" if is_postgres else "IFNULL"
            sql = (
                f"SELECT\n"
                f"  ABS(s.total - t.total) AS diff,\n"
                f"  s.total AS src_total,\n"
                f"  t.total AS tgt_total\n"
                f"FROM (SELECT SUM({null_fn}({cname},0)) AS total FROM {src_tbl}) s,\n"
                f"     (SELECT SUM({null_fn}({cname},0)) AS total FROM {tgt_tbl}) t\n"
                f"-- PASS ì¡°ê±´: diff = 0"
            )
            rules.append({
                "rule_name":     f"{src_tbl}_{cname}_SUM_MATCH",
                "rule_type":     "sum_match",
                "tier":          2,
                "severity":      "CRITICAL",
                "source_table":  src_tbl,
                "target_table":  tgt_tbl,
                "target_column": cname,
                "sql":           sql,
                "reason":        f"'{cname}'ì€ {domain} ì»¬ëŸ¼ â€” ì†ŒìŠ¤Â·íƒ€ê²Ÿ í•©ê³„ ì¼ì¹˜ í•„ìˆ˜.",
                "auto_generated": True,
            })

    return rules
